{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only the phone/word-level mic (production) TextGrids need to be force-aligned. The rest can be mostly automated using a match filter and fuzzy string matching. That's what this notebook does, it makes:\n",
    "\n",
    "* Sentence-level production TextGrids\n",
    "* Phone/word/sentence-level perception TextGrids\n",
    "\n",
    "**Please manually check your forced-aligned phone/word mic TextGrids for accuracy before creating these.** If you skip this step, your results will look terrible. Also, add a third tier to the phone/word mic TextGrids named \"task\" that denotes when audio is part of the task and when it's off-task banter between the participant and researchers/medical staff. (The TextGrids provided in this repo are all accurate) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import csv\n",
    "import re\n",
    "import sys\n",
    "sys.path.append(\"./\")\n",
    "import textgrid\n",
    "from fuzzywuzzy import fuzz\n",
    "from praatio import tgio\n",
    "import warnings\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local paths, please update accordingly\n",
    "git_path = '/path/to/git/kurteff2024_code/'\n",
    "data_path = '/path/to/bids/dataset/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change these values accordingly\n",
    "subj = \"TCH14\"\n",
    "block = \"B12\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Production (mic) sentence-level grids\n",
    "You will need:\n",
    "\n",
    "1. Accurate phone/word-level mic TextGrids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read sentences from log file\n",
    "blockid = \"_\".join([subj,block])\n",
    "transcript_folder = os.path.join(git_path,\"preprocessing\",\"events\",\"transcripts\",subj,blockid)\n",
    "log_path = os.path.join(git_path,\"preprocessing\",\"events\",\"logfiles\",f\"{blockid}.txt\")\n",
    "if os.path.isfile(log_path) and os.path.isdir(transcript_folder):\n",
    "    transcript_path = os.path.join(transcript_folder,f\"{blockid}_mic.txt\")\n",
    "    if os.path.isfile(transcript_path):\n",
    "        with open(log_path,'r') as f:\n",
    "            next(f), next(f), next(f) # Skip the header\n",
    "            d = csv.DictReader(f,delimiter=\"\\t\")\n",
    "            sentences = np.array(\n",
    "                [[r['MOCHARead']] + ['{NS}','{NS}'] for r in d if r['TrialPart']=='readRepeat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fuzzy_thresh = 75 # % match for the fuzzy text matching package. Adjust if you're having issues\n",
    "match_sentences = np.array([re.sub(r'[^\\w\\s]','',s).upper() for s in sentences[:,0]])\n",
    "n_sentences = match_sentences.shape[0]\n",
    "phone_tg_fpath = os.path.join(\n",
    "    git_path,\"preprocessing\",\"events\",\"textgrids\",subj,blockid,f\"{blockid}_mic.TextGrid\")\n",
    "sentence_tg_fpath = os.path.join(\n",
    "    git_path,\"preprocessing\",\"events\",\"textgrids\",subj,blockid,f\"{blockid}_mic_sentence.TextGrid\")\n",
    "if os.path.exists(sentence_tg_fpath):\n",
    "    print(\"Mic sentence TextGrid already exists\")\n",
    "else:\n",
    "    with open(phone_tg_fpath,'r') as f:\n",
    "        phone_tg = textgrid.TextGrid(f.read())\n",
    "        task_times = phone_tg.tiers[2].simple_transcript\n",
    "    word_transcript = np.array(phone_tg.tiers[1].simple_transcript)\n",
    "    word_onsets = word_transcript[:,0].astype(float); word_offsets = word_transcript[:,1].astype(float)\n",
    "    words = np.array([re.sub(r'[^\\w\\s]','',w) for w in word_transcript[:,2]])\n",
    "    nonword_inds = np.array([i for i,w in enumerate(words) if w in ['NS','sp','CG','LG','BR','SL','LS']])\n",
    "    word_onsets = np.delete(word_onsets,nonword_inds); word_offsets = np.delete(word_offsets,nonword_inds)\n",
    "    words = np.delete(words,nonword_inds)\n",
    "    task_onsets = np.array([float(r[0]) for r in task_times if r[2] == 'task'])\n",
    "    task_offsets = np.array([float(r[1]) for r in task_times if r[2] == 'task'])\n",
    "    task_times = np.array([[t, task_offsets[i]] for i,t in enumerate(task_onsets)])\n",
    "    task_inds = np.hstack((\n",
    "        [[i for i,o in enumerate(\n",
    "            word_onsets) if o >= interval[0] and o < interval[1]] for interval in task_times]\n",
    "    ))\n",
    "    words = words[task_inds]\n",
    "    word_onsets = word_onsets[task_inds]; word_offsets = word_offsets[task_inds]; first_word = word_onsets[0]\n",
    "    with open(log_path,'r') as f:\n",
    "        next(f), next(f), next(f)\n",
    "        d = csv.DictReader(f,delimiter='\\t')\n",
    "        sentence_onsets = np.array([[r['Time']] for r in d if r['TrialPart']=='readRepeat']).astype(float)\n",
    "    sentence_onsets = (sentence_onsets - sentence_onsets[0] + first_word).squeeze()\n",
    "    file_time = 0.; all_match_onsets, all_match_offsets, all_match_transcriptions = [], [], []\n",
    "    for i,sen in enumerate(match_sentences):\n",
    "        sentence_complete = False; first_two_words = sen.split()[:2]; last_two_words = sen.split()[-2:]\n",
    "        for ii, word in enumerate(words):\n",
    "            if word_onsets[ii] >= file_time and word_offsets[ii] <= file_time + 50:\n",
    "                if ii == 0:\n",
    "                    prev_word = ''; next_word = words[ii+1]\n",
    "                elif ii >= words.shape[0]-1:\n",
    "                    prev_word = words[ii-1]; next_word = ''\n",
    "                else:\n",
    "                    prev_word = words[ii-1]; next_word = words[ii+1]\n",
    "                if fuzz.ratio(' '.join([word,next_word]), ' '.join(first_two_words)) > fuzzy_thresh:\n",
    "                    match_sentence_onset = word_onsets[ii]; sen_onset_idx = ii\n",
    "                if (ii>0) & (fuzz.ratio(' '.join([prev_word,word]), ' '.join(last_two_words)) > fuzzy_thresh):\n",
    "                    if not sentence_complete:\n",
    "                        sen_offset_idx = ii\n",
    "                        matched_sen = words[sen_onset_idx:sen_offset_idx+1]\n",
    "                        matched_sen_onset = word_onsets[sen_onset_idx]\n",
    "                        matched_sen_offset = word_offsets[sen_offset_idx]\n",
    "                        sentence_complete = True; file_time = matched_sen_offset\n",
    "        if not sentence_complete:\n",
    "            # Try to get the sentence end another way. This might trigger when what the participant said\n",
    "            # deviates heavily from the stimulus (i.e., they made a lot of errors while reading).\n",
    "            approx_sentence_onset = sentence_onsets[i]-10; approx_sentence_offset = sentence_onsets[i]+40\n",
    "            approx_word_matches = np.intersect1d(np.where(word_onsets >= approx_sentence_onset)[0],\n",
    "                np.where(word_offsets <= approx_sentence_offset)[0])\n",
    "            fuzz_onset, fuzz_offset = [], []\n",
    "            for ii in approx_word_matches:\n",
    "                if ii == 0:\n",
    "                    prev_word = ''; next_word = words[ii+1]\n",
    "                elif ii >= words.shape[0]-1:\n",
    "                    prev_word = words[ii-1]; next_word = ''\n",
    "                else:\n",
    "                    prev_word = words[ii-1]; next_word = words[ii+1]\n",
    "                fuzz_onset.append(fuzz.ratio(' '.join([words[ii], next_word]), ' '.join(first_two_words)))\n",
    "                fuzz_offset.append(fuzz.ratio(' '.join([prev_word, words[ii]]), ' '.join(last_two_words)))\n",
    "            sen_onset_idx = approx_word_matches[np.array(fuzz_onset).argmax()]\n",
    "            sen_offset_idx = approx_word_matches[np.array(fuzz_offset).argmax()]\n",
    "            matched_sen = words[sen_onset_idx:sen_offset_idx+1]\n",
    "            matched_sen_onset = word_onsets[sen_onset_idx]; matched_sen_offset = word_offsets[sen_offset_idx]\n",
    "            file_time = matched_sen_offset\n",
    "            warnings.warn(f\"\"\"\n",
    "                Couldn't find a match for sentence {sen} using standard procedure.\n",
    "                The likely cause is the participant made too many errors for fuzzy matching to work.\n",
    "\n",
    "                After trying an alternate matching method, the best matched sentence transcription is:\n",
    "                {' '.join(matched_sen)}\n",
    "                Inserting sentence '{' '.join(matched_sen)}' in sentence TextGrid between\n",
    "                {matched_sen_onset} s and {matched_sen_offset} s.\n",
    "\n",
    "                Please manually confirm this is accurate!\n",
    "            \"\"\")\n",
    "        all_match_onsets.append(matched_sen_onset); all_match_offsets.append(matched_sen_offset)\n",
    "        all_match_transcriptions.append(' '.join(matched_sen))\n",
    "    sentence_textgrid = []\n",
    "    for i, s in enumerate(all_match_transcriptions):\n",
    "        if i == 0:\n",
    "            sentence_textgrid.append([0., all_match_onsets[i], 'sp'])\n",
    "        sentence_textgrid.append([all_match_onsets[i], all_match_offsets[i], s])\n",
    "        if i == len(all_match_transcriptions)-1:\n",
    "            sentence_textgrid.append([all_match_offsets[i], int(word_transcript[-1][1]), 'sp'])\n",
    "        else:\n",
    "            sentence_textgrid.append([all_match_offsets[i], all_match_onsets[i+1], 'sp'])\n",
    "    output_tg = tgio.Textgrid(); sentence_tier = tgio.IntervalTier('sentences', sentence_textgrid)\n",
    "    output_tg.addTier(sentence_tier); output_tg.save(sentence_tg_fpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perception (spkr) sentence-level TextGrids\n",
    "You will need:\n",
    "\n",
    "1. Accurate sentence-level production TextGrids\n",
    "2. Click eventfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_thresh = 0.5 # adjust\n",
    "spkr_wav_fpath = os.path.join(data_path,f\"sub-{subj}\",blockid,\"audio\",f\"{blockid}_spkr.wav\")\n",
    "mic_wav_fpath = os.path.join(data_path,f\"sub-{subj}\",blockid,\"audio\",f\"{blockid}_mic.wav\")\n",
    "mic_sentence_tg_fpath = os.path.join(git_path,\"preprocessing\",\"events\",\"textgrids\",subj,blockid,\n",
    "                                     f\"{blockid}_mic_sentence.TextGrid\")\n",
    "spkr_fs, spkr_audio = scipy.io.wavfile.read(spkr_wav_fpath)\n",
    "if spkr_fs != 11025:\n",
    "    spkr_audio = scipy.signal.resample(spkr_audio, int((spkr_audio.shape[0]/spkr_fs)*11025))[:,0]\n",
    "    scipy.io.wavfile.write(spkr_path, 11025, spkr_audio); spkr_fs = 11025\n",
    "else:\n",
    "    print(\"Spkr audio already at 11025 Hz.\")\n",
    "click_events = np.loadtxt(os.path.join(git_path,\"preprocessing\",\"events\",\"csv\",subj,blockid,\n",
    "                                       f\"{blockid}_click_eve.txt\"))\n",
    "for click in click_events:\n",
    "    click_onset = int(click[0]*spkr_fs); click_offset = int(click[1]*spkr_fs)\n",
    "    spkr_audio[click_onset:click_offset] = 0\n",
    "mic_fs, mic_audio = scipy.io.wavfile.read(mic_wav_fpath)\n",
    "spkr_audio = spkr_audio/spkr_audio.max(); mic_audio = mic_audio/mic_audio.max()\n",
    "with open(mic_sentence_tg_fpath) as f:\n",
    "    sen_tg = textgrid.TextGrid(f.read())\n",
    "mic_sentence_grid = np.array([s for s in sen_tg.tiers[0].simple_transcript if s[2] != 'sp'])\n",
    "spkr_match_onsets, spkr_match_offsets, spkr_match_transcriptions = [], [], []\n",
    "for i,mic_sentence in enumerate(mic_sentence_grid):\n",
    "    if playback_condition[i] == 'echolalia':\n",
    "        if fuzz.ratio(mic_sentence[2], mic_sentence_grid[0][2]) > 90:\n",
    "            print(f\"Skipping alignment for sentence {mic_sentence[2]}\")\n",
    "        else:\n",
    "            mic_sentence_onset = int(float(mic_sentence[0])*mic_fs)\n",
    "            mic_sentence_offset = int(float(mic_sentence[1])*mic_fs)\n",
    "            transcription = mic_sentence[2]\n",
    "            mic_sentence_clip = mic_audio[mic_sentence_onset:mic_sentence_offset]\n",
    "            matches = match_filter(mic_sentence_clip, spkr_audio, spkr_fs,\n",
    "                                   corr_thresh=corr_thresh, nreps=2, debug=True)\n",
    "            for match in matches[0]:\n",
    "                spkr_match_onsets.append(match[0]); spkr_match_offsets.append(match[1])\n",
    "                spkr_match_transcriptions.append(transcription)\n",
    "event_order = np.argsort(np.array(spkr_match_onsets).astype(float))\n",
    "spkr_matches = np.vstack((spkr_match_onsets,spkr_match_offsets,spkr_match_transcriptions)).T[event_order]\n",
    "spkr_sentence_tg_fpath = mic_sentence_tg_fpath.replace('mic','spkr') \n",
    "if os.path.isfile(spkr_sentence_tg_fpath):\n",
    "    print(\"Spkr sentence TextGrid already exists.\")\n",
    "else:\n",
    "    spkr_sentence_textgrid = []\n",
    "    for i, s in enumerate(spkr_matches[:,2]):\n",
    "        if i == 0:\n",
    "            spkr_sentence_textgrid.append([0., spkr_matches[i,0], 'sp'])\n",
    "        spkr_sentence_textgrid.append([spkr_matches[i,0], spkr_matches[i,1], s])\n",
    "        if i == len(spkr_matches)-1:\n",
    "            spkr_sentence_textgrid.append([spkr_matches[i,1], spkr_audio.shape[0]/spkr_fs, 'sp'])\n",
    "        else:\n",
    "            spkr_sentence_textgrid.append([spkr_matches[i,1], spkr_matches[i+1,0], 'sp'])\n",
    "    output_tg = tgio.Textgrid(); sentence_tier = tgio.IntervalTier('sentences', spkr_sentence_textgrid)\n",
    "    output_tg.addTier(sentence_tier); output_tg.save(spkr_sentence_tg_fpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perception (spkr) word and phone-level TextGrids\n",
    "\n",
    "You will need:\n",
    "\n",
    "1. Accurate sentence-level perception TextGrids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mic_ph_event_fpath = os.path.join(git_path,\"preprocessing\",\"events\",\"csv\",subj,blockid,\n",
    "                                  f\"{blockid}_mic_ph_all.txt\")\n",
    "mic_wr_event_fpath = os.path.join(git_path,\"preprocessing\",\"events\",\"csv\",subj,blockid,\n",
    "                                  f\"{blockid}_mic_wr_all.txt\")\n",
    "with open(spkr_sentence_tg_fpath) as f:\n",
    "    spkr_sen_tg = textgrid.TextGrid(f.read())\n",
    "spkr_sentence_grid = np.array([s for s in spkr_sen_tg.tiers[0].simple_transcript if s[2] != 'sp'])\n",
    "mic_ph_events = np.loadtxt(mic_ph_event_fpath, dtype=str, delimiter=\"\\t\")\n",
    "mic_ph_onsets = mic_ph_events[:,0].astype(float); mic_ph_offsets = mic_ph_events[:,1].astype(float)\n",
    "mic_ph_transcripts = mic_ph_events[:,3]\n",
    "mic_wr_events = np.loadtxt(mic_wr_event_fpath, dtype=str, delimiter=\"\\t\")\n",
    "mic_wr_onsets = mic_wr_events[:,0].astype(float); mic_wr_offsets = mic_wr_events[:,1].astype(float)\n",
    "mic_wr_transcripts = mic_wr_events[:,3]\n",
    "spkr_phone_tier, spkr_word_tier = [], []\n",
    "spkr_phone_tier.append([0., float(spkr_sentence_grid[0][0]), 'sp'])\n",
    "spkr_word_tier.append([0., float(spkr_sentence_grid[0][0]), 'sp'])\n",
    "for i, sen in enumerate(spkr_sentence_grid):\n",
    "    spkr_onset = float(sen[0]); spkr_offset = float(sen[1]); transcript = sen[2]\n",
    "    mic_match_idx = np.where(np.array([s[2] for mi,s in enumerate(\n",
    "        mic_sentence_grid) if playback_condition[mi] == 'echolalia'])==transcript)[0][0]\n",
    "    mic_match_onset = float(mic_sentence_grid[mic_match_idx,0])\n",
    "    mic_match_offset = float(mic_sentence_grid[mic_match_idx,1])\n",
    "    mic_sen_ph_matches = np.intersect1d(np.where(mic_ph_onsets >= mic_match_onset)[0],\n",
    "        np.where(mic_ph_offsets <= mic_match_offset)[0])\n",
    "    spkr_ph_onsets = (mic_ph_onsets[mic_sen_ph_matches] - mic_ph_onsets[mic_sen_ph_matches][0]) + spkr_onset\n",
    "    spkr_ph_offsets = (mic_ph_offsets[mic_sen_ph_matches] - mic_ph_onsets[mic_sen_ph_matches][0]) + spkr_onset\n",
    "    for si, mi in enumerate(mic_sen_ph_matches):\n",
    "        spkr_phone_tier.append([spkr_ph_onsets[si], spkr_ph_offsets[si], mic_ph_transcripts[mi]])\n",
    "    mic_sen_wr_matches = np.intersect1d(\n",
    "        np.where(mic_wr_onsets >= mic_match_onset)[0],\n",
    "        np.where(mic_wr_offsets <= mic_match_offset)[0]\n",
    "    )\n",
    "    spkr_wr_onsets = (mic_wr_onsets[mic_sen_wr_matches] - mic_wr_onsets[mic_sen_wr_matches][0]) + spkr_onset\n",
    "    spkr_wr_offsets = (mic_wr_offsets[mic_sen_wr_matches] - mic_wr_onsets[mic_sen_wr_matches][0]) + spkr_onset\n",
    "    for si, mi in enumerate(mic_sen_wr_matches):\n",
    "        spkr_word_tier.append([spkr_wr_onsets[si], spkr_wr_offsets[si], mic_wr_transcripts[mi]])\n",
    "spkr_phone_tier.append([float(spkr_sentence_grid[-1][0]), spkr_audio.shape[0]/spkr_fs, 'sp'])\n",
    "spkr_word_tier.append([float(spkr_sentence_grid[-1][0]), spkr_audio.shape[0]/spkr_fs, 'sp'])\n",
    "spkr_phone_tg_fpath = phone_tg_fpath.replace('mic','spkr')\n",
    "if os.path.isfile(spkr_phone_tg_fpath):\n",
    "    print(\"Spkr phone/word TextGrid already exists.\")\n",
    "else:\n",
    "    output_tg = tgio.Textgrid()\n",
    "    phone_tier = tgio.IntervalTier('phone', spkr_phone_tier); word_tier = tgio.IntervalTier('word', spkr_word_tier)\n",
    "    output_tg.addTier(phone_tier); output_tg.addTier(word_tier)\n",
    "    output_tg.save(spkr_phone_tg_fpath)\n",
    "    with open(spkr_phone_tg_fpath) as f:\n",
    "        spkr_tg = textgrid.TextGrid(f.read())\n",
    "    spkr_phone_tg = spkr_tg.tiers[0].simple_transcript\n",
    "    spkr_phones = []; for row in spkr_phone_tg:\n",
    "        if row[2] == '':\n",
    "            spkr_phones.append([row[0], row[1], 'sp'])\n",
    "        else:\n",
    "            spkr_phones.append([row[0], row[1], row[2]])\n",
    "    spkr_word_tg = spkr_tg.tiers[1].simple_transcript\n",
    "    spkr_words = []; for row in spkr_word_tg:\n",
    "        if row[2] == '':\n",
    "            spkr_words.append([row[0], row[1], 'sp'])\n",
    "        else:\n",
    "            spkr_words.append([row[0], row[1], row[2]])\n",
    "    output_tg = tgio.Textgrid()\n",
    "    phone_tier = tgio.IntervalTier('phone', spkr_phones); word_tier = tgio.IntervalTier('word', spkr_words)\n",
    "    output_tg.addTier(phone_tier); output_tg.addTier(word_tier); output_tg.save(spkr_phone_tg_fpath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
