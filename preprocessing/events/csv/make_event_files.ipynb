{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook uses the TextGrids to create event files for epoching the data in MNE.\n",
    "\n",
    "**Please manually check your forced-aligned TextGrids for accuracy before creating these event files.** If you skip this step, your results will look terrible. (The TextGrids provided in this repo are all accurate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import csv\n",
    "import re\n",
    "import sys\n",
    "import scipy\n",
    "from glob import glob\n",
    "sys.path.append(\"../textgrids/\")\n",
    "import textgrid\n",
    "sys.path.append(\"./\")\n",
    "import match_filter\n",
    "from fuzzywuzzy import fuzz\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local paths, please update accordingly\n",
    "git_path = '/path/to/git/kurteff2024_code/'\n",
    "data_path = '/path/to/bids/dataset/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change these values accordingly\n",
    "subj = \"TCH14\"\n",
    "block = \"B12\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Click eventfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_thresh = 0.15 # adjust if you aren't finding the proper number of matches\n",
    "nreps = 100 # adjust: n_trials * 2\n",
    "\n",
    "spkr_fs, spkr_audio = scipy.io.wavfile.read(spkr_path)\n",
    "click_fs, click_audio = scipy.io.wavfile.read(\n",
    "    os.path.join(git_path, \"onsetProd\", \"ipad\", \"ipad_dcmc\", \"SupplementalFiles\", \"click.wav\")\n",
    ")\n",
    "click_audio = scipy.signal.resample(click_audio, int((click_audio.shape[0]/click_fs)*spkr_fs))[:,0]\n",
    "click_audio = click_audio/click_audio.max()\n",
    "spkr_audio = spkr_audio/spkr_audio.max()\n",
    "matches = match_filter(click_audio, spkr_audio, spkr_fs, corr_thresh=corr_thresh, nreps=nreps, debug=True)\n",
    "click_onsets = np.sort(matches[0][:,0]); click_offsets = np.sort(matches[0][:,1])\n",
    "click_eventfile_fpath = os.path.join(git_path,\"preprocessing\",\"events\",\"csv\",subj,blockid,\n",
    "                                     f\"{blockid}_click_eve.txt\")\n",
    "if os.path.isfile(click_eventfile_fpath):\n",
    "    print(\"Click eventfile already exists\")\n",
    "else:\n",
    "    click_eventfile_txt = np.vstack((\n",
    "        click_onsets, click_offsets, np.ones(click_onsets.shape[0]))).astype(float).T\n",
    "    np.savetxt(click_eventfile_fpath, click_eventfile_txt, fmt=\"%.3f\", delimiter='\\t', newline='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Production (mic) eventfiles\n",
    "You will need:\n",
    "1. Accurate phone, word, and sentence level mic TextGrids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "easy_reading = ['S0017','S0018','S0021','S0023','S0024','TCH8','TCH14']; easy_reading = subj in easy_reading\n",
    "blockid = \"_\".join([subj,block])\n",
    "sentence_tg_fpath = os.path.join(git_path,\"preprocessing\",\"events\",\"textgrids\",subj,blockid,\n",
    "                                 f\"{blockid}_mic_sentence.TextGrid\")\n",
    "log_path = os.path.join(git_path,\"preprocessing\",\"events\",\"logfiles\",f\"{blockid}.txt\")\n",
    "phoneme_ids = np.loadtxt(os.path.join(git_path,\"preprocessing\",\"events\",\"csv\",\"phonemes.txt\"),\n",
    "                         dtype=str, delimiter='\\n')\n",
    "word_ids = np.loadtxt(os.path.join(git_path,\"preprocessing\",\"events\",\"csv\",\"words.txt\"),\n",
    "                      dtype=str, delimiter='\\n')\n",
    "sn_ext = \"sentences_easyreading.txt\" if easy_reading else \"sentences.txt\"\n",
    "sentence_ids = np.loadtxt(os.path.join(git_path,\"preprocessing\",\"events\",\"csv\",sn_ext),\n",
    "                          dtype=str, delimiter='\\n')\n",
    "sentence_ids = [re.sub(r'[^\\w\\s]','', row).upper() for row in sentence_ids]\n",
    "with open(log_path,'r') as f:\n",
    "    next(f), next(f), next(f); d = csv.DictReader(f,delimiter='\\t')\n",
    "    playback_condition = np.array(([[r['CurrentBlock']] for r in d if r['TrialPart']=='listen'])).squeeze()\n",
    "with open(sentence_tg_fpath) as f:\n",
    "    sen_tg = textgrid.TextGrid(f.read())\n",
    "sentence_grid = np.array([s for s in sen_tg.tiers[0].simple_transcript if s[2] != 'sp'])\n",
    "with open(phone_tg_fpath,'r') as f:\n",
    "    phone_tg = textgrid.TextGrid(f.read())\n",
    "word_grid = np.array(phone_tg.tiers[1].simple_transcript)\n",
    "word_onsets = word_grid[:,0].astype(float); word_offsets = word_grid[:,1].astype(float)\n",
    "words = np.array([re.sub(r'[^\\w\\s]','',w) for w in word_grid[:,2]])\n",
    "word_idxs = [i for i,w in enumerate(words) if w not in ['NS','sp','CG','LG','BR','SL','LS']]\n",
    "word_onsets = word_onsets[word_idxs]; word_offsets = word_offsets[word_idxs]; words = words[word_idxs]\n",
    "task_times = phone_tg.tiers[2].simple_transcript\n",
    "task_onsets = np.array([float(r[0]) for r in task_times if r[2] == 'task'])\n",
    "task_offsets = np.array([float(r[1]) for r in task_times if r[2] == 'task'])\n",
    "task_times = np.array([[t, task_offsets[i]] for i,t in enumerate(task_onsets)])\n",
    "task_inds = np.hstack(([[i for i,o in enumerate(\n",
    "    word_onsets) if o >= interval[0] and o < interval[1]] for interval in task_times]))\n",
    "words = words[task_inds]; word_onsets = word_onsets[task_inds]; word_offsets = word_offsets[task_inds]\n",
    "phone_grid = np.array(phone_tg.tiers[0].simple_transcript)\n",
    "phone_onsets = phone_grid[:,0].astype(float); phone_offsets = phone_grid[:,1].astype(float)\n",
    "phones = phone_grid[:,2]\n",
    "phone_idxs = [i for i,p in enumerate(phones) if p not in ['ns','sp','cg','lg','br','sl','ls']]\n",
    "phone_onsets = phone_onsets[phone_idxs]; phone_offsets = phone_offsets[phone_idxs]; phones = phones[phone_idxs]\n",
    "task_inds = np.hstack(([[i for i,o in enumerate(\n",
    "    phone_onsets) if o >= interval[0] and o < interval[1]] for interval in task_times]))\n",
    "phones = phones[task_inds]; phone_onsets = phone_onsets[task_inds]; phone_offsets = phone_offsets[task_inds]\n",
    "sentence_events, word_events, phone_events = [], [], []\n",
    "sentence_events_echo, word_events_echo, phone_events_echo = [], [], []\n",
    "sentence_events_shuff, word_events_shuff, phone_events_shuff = [], [], []\n",
    "\n",
    "for i, sen in enumerate(sentence_grid):\n",
    "    onset = float(sen[0]); offset = float(sen[1]); transcript = sen[2]\n",
    "    event_id = np.array([fuzz.ratio(transcript, s) for s in sentence_ids]).argmax()\n",
    "    if [fuzz.ratio(transcript,s) for s in sentence_ids][event_id] < fuzzy_thresh:\n",
    "        warnings.warn(f\"\"\"\n",
    "            Fuzzy matching for sentence '{transcript}' falls below fuzzy_thresh.\n",
    "            It was matched to MOCHA sentence {sen}.\n",
    "            If this is not accurate, please manually adjust the sentence eventfiles.\n",
    "        \"\"\")\n",
    "    sentence_events.append([onset, offset, event_id, transcript])\n",
    "    if playback_condition[i] == 'echolalia':\n",
    "        sentence_events_echo.append([onset, offset, event_id, transcript])\n",
    "    elif playback_condition[i] == 'shuffled':\n",
    "        sentence_events_shuff.append([onset, offset, event_id, transcript])\n",
    "    sen_word_idxs = np.intersect1d(np.where(word_onsets >= onset)[0], np.where(word_offsets <= offset)[0])\n",
    "    for wi in sen_word_idxs:\n",
    "        word_event_id = np.where(word_ids == words[wi])[0][0] if words[wi] in word_ids else 88888\n",
    "        word_events.append([word_onsets[wi], word_offsets[wi], word_event_id, words[wi]])\n",
    "        if playback_condition[i] == 'echolalia':\n",
    "            word_events_echo.append([word_onsets[wi], word_offsets[wi], word_event_id, words[wi]])\n",
    "        elif playback_condition[i] == 'shuffled':\n",
    "            word_events_shuff.append([word_onsets[wi], word_offsets[wi], word_event_id, words[wi]])\n",
    "    sen_phone_idxs = np.intersect1d(np.where(phone_onsets >= onset)[0],np.where(phone_offsets <= offset)[0])\n",
    "    for pi in sen_phone_idxs:\n",
    "        if phones[pi] in phoneme_ids:\n",
    "            phone_event_id = np.where(phoneme_ids == phones[pi])[0][0]\n",
    "        else:\n",
    "            phone_event_id = 88888; warnings.warn(\n",
    "                f\"Unknown phoneme encountered at {phone_onsets[pi]}, please manually correct TextGrid.\")\n",
    "            \n",
    "        phone_events.append([phone_onsets[pi], phone_offsets[pi], phone_event_id, phones[pi]])\n",
    "        if playback_condition[i] == 'echolalia':\n",
    "            phone_events_echo.append([phone_onsets[pi], phone_offsets[pi], phone_event_id, phones[pi]])\n",
    "        elif playback_condition[i] == 'shuffled':\n",
    "            phone_events_shuff.append([phone_onsets[pi], phone_offsets[pi], phone_event_id, phones[pi]])\n",
    "event_folder = os.path.join(git_path,\"preprocessing\",\"events\",subj,blockid)\n",
    "if len(glob(os.path.join(event_folder, \"*mic*\"))) > 0:\n",
    "    print(\"Mic eventfiles already exist.\")\n",
    "else:\n",
    "    np.savetxt(os.path.join(event_folder,f\"{blockid}_mic_sn_all.txt\"),\n",
    "               sentence_events, fmt=\"%s\", delimiter=\"\\t\", newline=\"\\n\")\n",
    "    np.savetxt(os.path.join(event_folder,f\"{blockid}_mic_sn_el.txt\"),\n",
    "               sentence_events_echo, fmt=\"%s\", delimiter=\"\\t\", newline=\"\\n\")\n",
    "    np.savetxt(os.path.join(event_folder,f\"{blockid}_mic_sn_sh.txt\"),\n",
    "               sentence_events_shuff, fmt=\"%s\", delimiter=\"\\t\", newline=\"\\n\")\n",
    "    np.savetxt(os.path.join(event_folder,f\"{blockid}_mic_wr_all.txt\"),\n",
    "               word_events, fmt=\"%s\", delimiter=\"\\t\", newline=\"\\n\")\n",
    "    np.savetxt(os.path.join(event_folder,f\"{blockid}_mic_wr_el.txt\"),\n",
    "               word_events_echo, fmt=\"%s\", delimiter=\"\\t\", newline=\"\\n\")\n",
    "    np.savetxt(os.path.join(event_folder,f\"{blockid}_mic_wr_sh.txt\"),\n",
    "               word_events_shuff, fmt=\"%s\", delimiter=\"\\t\", newline=\"\\n\")\n",
    "    np.savetxt(os.path.join(event_folder,f\"{blockid}_mic_ph_all.txt\"),\n",
    "               phone_events, fmt=\"%s\", delimiter=\"\\t\", newline=\"\\n\")\n",
    "    np.savetxt(os.path.join(event_folder,f\"{blockid}_mic_ph_el.txt\"),\n",
    "               phone_events_echo, fmt=\"%s\", delimiter=\"\\t\", newline=\"\\n\")\n",
    "    np.savetxt(os.path.join(event_folder,f\"{blockid}_mic_ph_sh.txt\"),\n",
    "               phone_events_shuff, fmt=\"%s\", delimiter=\"\\t\", newline=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perception (spkr) eventfiles\n",
    "You will need:\n",
    "\n",
    "1. Accurate production TextGrids (all)\n",
    "2. Accurate perception TextGrids (all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spkr_phone_tg_fpath = os.path.join(\n",
    "    git_path,\"preprocessing\",\"events\",\"textgrids\",subj,blockid,f\"{blockid}_spkr.TextGrid\")\n",
    "spkr_sen_tg_fpath = os.path.join(\n",
    "    git_path,\"preprocessing\",\"events\",\"textgrids\",subj,blockid,f\"{blockid}_spkr_sentence.TextGrid\")\n",
    "shuff_start = float(sen_tg[np.where(playback_condition=='shuffled')[0][0],0])\n",
    "spkr_phone_events = []; spkr_phone_events_echo, spkr_phone_events_shuff = [], []\n",
    "with open(spkr_phone_tg_fpath,'r') as f:\n",
    "    spkr_phone_tg = textgrid.TextGrid(f.read())\n",
    "    spkr_phone_tier = spkr_phone_tg.tiers[0].simple_transcript\n",
    "    spkr_word_tier = spkr_phone_tg.tiers[1].simple_transcript\n",
    "with open(spkr_sen_tg_fpath,'r') as f:\n",
    "    spkr_sen_tg = textgrid.TextGrid(f.read())\n",
    "    spkr_sen_tier = spkr_sen_tg.tiers[0].simple_transcript\n",
    "for event in spkr_phone_tier[1:-1]:\n",
    "    onset = event[0]; offset = event[1]; transcript = event[2]\n",
    "    phone_id = np.where(phoneme_ids == event[2])[0][0]\n",
    "    spkr_phone_events.append([onset,offset,phone_id,transcript])\n",
    "    if onset >= shuff_start:\n",
    "        spkr_phone_events_shuff.append([onset,offset,phone_id,transcript])\n",
    "    else:\n",
    "        spkr_phone_events_echo.append([onset,offset,phone_id,transcript])\n",
    "spkr_word_events = []; spkr_word_events_echo, spkr_word_events_shuff = [], []\n",
    "for event in spkr_word_tier[1:-1]:\n",
    "    onset = event[0]; offset = event[1]; transcript = event[2]\n",
    "    word_id = np.where(word_ids == event[2])[0][0] if event[2] in list(word_ids) else 88888\n",
    "    spkr_word_events.append([onset,offset,word_id,transcript])\n",
    "    if onset >= shuff_start:\n",
    "        spkr_word_events_shuff.append([onset,offset,word_id,transcript])\n",
    "    else:\n",
    "        spkr_word_events_echo.append([onset,offset,word_id,transcript])\n",
    "spkr_sen_events = []; spkr_sen_events_echo, spkr_sen_events_shuff = [], []\n",
    "for event in spkr_sen_tier[1:-1]:\n",
    "    onset = float(event[0]); offset = float(event[1]); transcript = event[2]\n",
    "    event_id = np.array([fuzz.ratio(transcript, s) for s in sentence_ids]).argmax()\n",
    "    if [fuzz.ratio(transcript,s) for s in sentence_ids][event_id] < fuzzy_thresh:\n",
    "        warnings.warn(f\"\"\"\n",
    "        Fuzzy matching for sentence '{transcript}' falls below fuzzy_thresh.\n",
    "        It was matched to MOCHA sentence {sen}.\n",
    "        If this is not accurate, please manually adjust the sentence eventfiles.\n",
    "        \"\"\")\n",
    "    spkr_sen_events.append([onset,offset,event_id,transcript])\n",
    "    if onset >= shuff_start:\n",
    "        spkr_sen_events_shuff.append([onset,offset,event_id,transcript])\n",
    "    else:\n",
    "        spkr_sen_events_echo.append([onset,offset,event_id,transcript])\n",
    "if len(glob(os.path.join(event_folder,\"*spkr*\"))) > 0:\n",
    "    print(\"Spkr eventfiles already exist.\")\n",
    "else:\n",
    "    np.savetxt(os.path.join(event_folder,f\"{blockid}_spkr_sn_all.txt\"),\n",
    "               spkr_sen_events, fmt=\"%s\", delimiter=\"\\t\", newline=\"\\n\")\n",
    "    np.savetxt(os.path.join(event_folder,f\"{blockid}_spkr_sn_el.txt\"),\n",
    "               spkr_sen_events_echo, fmt=\"%s\", delimiter=\"\\t\", newline=\"\\n\")\n",
    "    np.savetxt(os.path.join(event_folder,f\"{blockid}_spkr_sn_sh.txt\"),\n",
    "               spkr_sen_events_shuff, fmt=\"%s\", delimiter=\"\\t\", newline=\"\\n\")\n",
    "    np.savetxt(os.path.join(event_folder,f\"{blockid}_spkr_wr_all.txt\"),\n",
    "               spkr_word_events, fmt=\"%s\", delimiter=\"\\t\", newline=\"\\n\")\n",
    "    np.savetxt(os.path.join(event_folder,f\"{blockid}_spkr_wr_el.txt\"),\n",
    "               spkr_word_events_echo, fmt=\"%s\", delimiter=\"\\t\", newline=\"\\n\")\n",
    "    np.savetxt(os.path.join(event_folder,f\"{blockid}_spkr_wr_sh.txt\"),\n",
    "               spkr_word_events_shuff, fmt=\"%s\", delimiter=\"\\t\", newline=\"\\n\")\n",
    "    np.savetxt(os.path.join(event_folder,f\"{blockid}_spkr_ph_all.txt\"),\n",
    "               spkr_phone_events, fmt=\"%s\", delimiter=\"\\t\", newline=\"\\n\")\n",
    "    np.savetxt(os.path.join(event_folder,f\"{blockid}_spkr_ph_el.txt\"),\n",
    "               spkr_phone_events_echo, fmt=\"%s\", delimiter=\"\\t\", newline=\"\\n\")\n",
    "    np.savetxt(os.path.join(event_folder,f\"{blockid}_spkr_ph_sh.txt\"),\n",
    "               spkr_phone_events_shuff, fmt=\"%s\", delimiter=\"\\t\", newline=\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
