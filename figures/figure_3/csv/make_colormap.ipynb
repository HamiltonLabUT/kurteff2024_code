{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths - Update locally!\n",
    "git_path = '/path/to/git/kurteff2024_code/'\n",
    "data_path = '/path/to/bids/dataset/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "import h5py\n",
    "import pymf3\n",
    "\n",
    "from img_pipe import img_pipe\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import rcParams as rc\n",
    "import matplotlib.patheffects as PathEffects\n",
    "rc['pdf.fonttype'] = 42\n",
    "plt.style.use('seaborn')\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "sys.path.append(os.path.join(git_path,\"figures\"))\n",
    "import plotting_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjs = [s for s in os.listdir(\n",
    "    os.path.join(git_path,\"preprocessing\",\"events\",\"csv\")) if \"TCH\" in s or \"S0\" in s]\n",
    "exclude = [\"TCH8\"]\n",
    "no_imaging = [\"S0010\"]\n",
    "subjs = [s for s in subjs if s not in exclude]\n",
    "\n",
    "blocks = {\n",
    "    s: [\n",
    "        b.split(\"_\")[-1] for b in os.listdir(os.path.join(\n",
    "            git_path,\"analysis\",\"events\",\"csv\",s)) if f\"{s}_B\" in b and os.path.isfile(os.path.join(\n",
    "            git_path,\"analysis\",\"events\",\"csv\",s,b,f\"{b}_spkr_sn_all.txt\"\n",
    "        ))\n",
    "    ] for s in subjs\n",
    "}\n",
    "\n",
    "hems = {s:[] for s in subjs}\n",
    "for s in subjs:\n",
    "    pt = img_pipe.freeCoG(f\"{s}_complete\",hem='stereo',subj_dir=data_path)\n",
    "    elecs = pt.get_elecs()['elecmatrix']\n",
    "    if sum(elecs[:,0] > 0) >= 1:\n",
    "        hems[s].append('rh')\n",
    "    if sum(elecs[:,0] < 0) >= 1:\n",
    "        hems[s].append('lh')\n",
    "\n",
    "color_palette = pd.read_csv(os.path.join(git_path,\"figures\",\"color_palette.csv\"))\n",
    "spkr_color = color_palette.loc[color_palette['color_id']=='perception']['hex'].values[0]\n",
    "mic_color = color_palette.loc[color_palette['color_id']=='production']['hex'].values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load cNMF results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load NMF results from h5\n",
    "bname = 'spkrmicclick'; epoch_types = ['spkr','mic','click']; plt_colors = [spkr_color,mic_color,click_color]\n",
    "nmf = dict(); nmf['resp'] = dict()\n",
    "h5_fpath = os.path.join(git_path,\"analysis\",\"cnmf\",\"h5\",f\"NMF_grouped_{bname}.hf5\")\n",
    "with h5py.File(h5_fpath,'r') as f:\n",
    "    num_bases = np.array(f.get('num_bases')); nmf['pve'] = np.array(f.get('pve'))\n",
    "    for nb in num_bases:\n",
    "        nmf[nb] = dict(); nmf[nb]['W'] = np.array(f.get(f'{nb}_bases/W'))\n",
    "        nmf[nb]['H'] = np.array(f.get(f'{nb}_bases/H'))\n",
    "    for epoch_type in epoch_types:\n",
    "        nmf['resp'][epoch_type] = np.array(f.get(f'resp/{epoch_type}'))\n",
    "nmf['ch_names'] = np.loadtxt(os.path.join(git_path,\"analysis\",\"cnmf\",\"h5\",\n",
    "                                          f\"NMF_grouped_{bname}_ch_names.txt\"),dtype=str)\n",
    "nmf['all_subjs'] = np.loadtxt(os.path.join(git_path,\"analysis\",\"cnmf\",\"h5\",\n",
    "                                           f\"NMF_grouped_{bname}_all_subjs.txt\"), dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert resp into a subject-by-subject format\n",
    "resp, ch_names = dict(), dict()\n",
    "for s in subjs:\n",
    "    nmf_inds = np.where(nmf['all_subjs']==s)[0]\n",
    "    if nmf_inds.shape[0] == 0:\n",
    "        warnings.warn(f\"Subject {s} missing from {bname} NMF, skipping...\")\n",
    "    else:\n",
    "        ch_names[s] = nmf['ch_names'][nmf_inds]; resp[s] = dict()\n",
    "        for epoch_type in epoch_types:\n",
    "            resp[s][epoch_type] = nmf['resp'][epoch_type][nmf_inds,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Truncate weights according to a kneepoint\n",
    "nmf['k'] = 9 # 86% PVE\n",
    "# clip nmf.W to k clusters, and reorder by weight\n",
    "clust = nmf[nmf['k']]; W = clust['W']; clusters = dict(); clusters['W'] = np.zeros(W.shape)\n",
    "clusters['all_subjs'] = np.zeros(W.shape).astype(str); clusters['ch_names'] = np.zeros(W.shape).astype(str)\n",
    "clusters['resp'] = {epoch_type:np.zeros((nmf['k'],W.shape[0],\n",
    "                                         nmf['resp'][epoch_types[0].shape[1]])) for epoch_type in epoch_types}\n",
    "clust_sort = np.argsort(W.sum(0))\n",
    "for ri,ai in enumerate(clust_sort): # relative/absolute index\n",
    "    sorted_idxs = np.flip(np.argsort(W[:,ai])); clusters['W'][:,ri] = W[:,ai][sorted_idxs]\n",
    "    clusters['all_subjs'][:,ri] = nmf['all_subjs'][sorted_idxs]\n",
    "    clusters['ch_names'][:,ri] = nmf['ch_names'][sorted_idxs]\n",
    "    for epoch_type in epoch_types:\n",
    "        clusters['resp'][epoch_type][ri,:] = nmf['resp'][epoch_type][sorted_idxs]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize weights between 0 and 1\n",
    "normed_wts = np.zeros(clusters['W'].shape)\n",
    "for i in np.arange(clusters['W'].shape[1]):\n",
    "    wtmin = clusters['W'][:,i].min()\n",
    "    normed_wts[:,i] = (clusters['W'][:,i]-wtmin)/(clusters['W'][:,i]-wtmin).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Within-cluster colormaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "within_cluster_cmap = dict()\n",
    "for clust in np.arange(nmf['k']):\n",
    "    within_cluster_cmap[clust] = [cm.Reds(w) for w in normed_wts[:,clust]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to csv\n",
    "save_clusters = [0, # Dual onset (these are zero-indexed)\n",
    "                 1, # Onset suppression\n",
    "                 2] # Pre-articulatory motor\n",
    "for hem in ['lh','rh']:\n",
    "    for s in [ss for s in subjs if hem in hems[ss]]:\n",
    "        blockid = \"_\".join([s,blocks[s][0]])\n",
    "        fif_ch_names = mne.io.read_raw_fif(os.path.join(data_path,f\"sub-{s}\",blockid,\"HilbAA_70to150_8band\",\n",
    "            \"ecog_hilbAA70to150.fif\"), preload=False, verbose=False).info['ch_names']\n",
    "        pt = img_pipe.freeCoG(f'{s}_complete',hem=hem, subj_dir=ip)\n",
    "        e, a = imaging_utils.clip_4mm_elecs(pt,hem=hem,elecfile_prefix=\"TDT_elecs_all_warped\")\n",
    "        e, a = imaging_utils.clip_outside_brain_elecs(pt,elecmatrix=e,anatomy=a,hem=hem,\n",
    "                                                      elecfile_prefix=\"TDT_elecs_all_warped\")\n",
    "        fs_ch_names = [aa[0][0] for aa in a]\n",
    "        for clust in save_clusters:\n",
    "            df = pd.DataFrame(columns=['subj','hem','ch_name','x','y','z','r','g','b','a'])\n",
    "            subj_idxs = list(np.where(clusters['all_subjs'][:,clust]==s)[0])\n",
    "            for idx in subj_idxs:\n",
    "                ch_name = clusters['ch_names'][idx,clust]\n",
    "                if ch_name != \"EKG1\":\n",
    "                    fif_idx = fif_ch_names.index(ch_name.replace(\"-\",\"\"))\n",
    "                    elecfile_idx = fs_ch_names.index(ch_name.replace(\"-\",\"\"))\n",
    "                    x,y,z = e[elecfile_idx,:]\n",
    "                    r,g,b,a = within_cluster_cmap[clust][idx]\n",
    "                    new_row = pd.DataFrame({'subj':[s],'hem':[hem],'ch_name':[ch],'x':[x],'y':[y],'z':[z],\n",
    "                                            'r':[r],'g':[g],'b':[b],'a':[a]})\n",
    "                    df = df.append(new_row, ignore_index=True)\n",
    "            df.to_csv(os.path.join(git_path,\"figures\",\"figure_3\",\"csv\",\n",
    "                                   f\"figure_3_cmap_within_clust_{clust+1}.csv\"),index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Across-cluster colormap\n",
    "Comparing cluster 1 (dual onset) to cluster 2 (onset suppression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap_2d = plt.imread(os.path.join(git_path,\"figures\",\"figure_3\",\"RdBuPr_splinesqrt22.png\"))\n",
    "across_cluster_cmap, across_cluster_values = dict(), dict(); completed_cmaps = []\n",
    "across_cluster_values['native'], across_cluster_values['norm'] = dict(), dict()\n",
    "for xc in np.arange(nmf['k']): # x-axis cluster\n",
    "    for yc in np.arange(nmf['k']): # y-axis cluster\n",
    "        if xc != yc:\n",
    "            # Don't compare diagonals\n",
    "            if [xc,yc] not in completed_cmaps and [yc,xc] not in completed_cmaps:\n",
    "                # If we have already made a colormap for this pair don't make it again\n",
    "                completed_cmaps.append([xc,yc])\n",
    "                x_ch_names = list(clusters['ch_names'][:,xc]); x_subjs = list(clusters['all_subjs'][:,xc])\n",
    "                x_ch_names_ext = [f\"{x_subjs[i]}_{c}\" for i,c in enumerate(x_ch_names)]\n",
    "                y_ch_names = list(clusters['ch_names'][:,yc]); y_subjs = list(clusters['all_subjs'][:,yc])\n",
    "                y_ch_names_ext = [f\"{y_subjs[i]}_{c}\" for i,c in enumerate(y_ch_names)]\n",
    "                x_W = clusters['W'][:,xc]; y_W = clusters['W'][:,yc]\n",
    "                # Reorder y_W so that the channels line up with each other\n",
    "                # This means the channel name follows xc not yc\n",
    "                y_inds = []\n",
    "                for ch in x_ch_names_ext:\n",
    "                    y_inds.append(y_ch_names_ext.index(ch))\n",
    "                y_W = y_W[y_inds]; across_cluster_values['native'][f\"{xc}-{yc}\"] = x_W - y_W\n",
    "                xymin = np.array([x_W.min(), y_W.min()]).min(); x_W = x_W-xymin; y_W = y_W-xymin\n",
    "                xymax = np.array([x_W.max(), y_W.max()]).max(); x_W = x_W/xymax; y_W = y_W/xymax\n",
    "                across_cluster_values['norm'][f\"{xc}-{yc}\"] = x_W - y_W\n",
    "                # axis 2 is RGB values so we can get them by indexing ax0 by xc and ax1 by yc\n",
    "                across_cluster_cmap[f\"{xc}-{yc}\"] = [\n",
    "                    cmap_2d[round(x_W[i]*255),round(y_W[i]*255),:] for i in np.arange(x_W.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to csv\n",
    "save_contrasts = ['0-1'] # Dual onset vs onset suppression\n",
    "for hem in ['lh','rh']:\n",
    "    for s in [ss for s in subjs if hem in hems[ss]]:\n",
    "        blockid = \"_\".join([s,blocks[s][0]])\n",
    "        fif_ch_names = mne.io.read_raw_fif(os.path.join(data_path,f\"sub-{s}\",blockid,\"HilbAA_70to150_8band\",\n",
    "            \"ecog_hilbAA70to150.fif\"), preload=False, verbose=False).info['ch_names']\n",
    "        pt = img_pipe.freeCoG(f'{s}_complete',hem=hem, subj_dir=ip)\n",
    "        e, a = imaging_utils.clip_4mm_elecs(pt,hem=hem,elecfile_prefix=\"TDT_elecs_all_warped\")\n",
    "        e, a = imaging_utils.clip_outside_brain_elecs(pt,elecmatrix=e,anatomy=a,hem=hem,\n",
    "                                                      elecfile_prefix=\"TDT_elecs_all_warped\")\n",
    "        fs_ch_names = [aa[0][0] for aa in a]\n",
    "        for contrast in save_contrasts:\n",
    "            xc, yc = [int(d) for d in contrast.split('-')]\n",
    "            df = pd.DataFrame(columns=['subj','hem','ch_name','x','y','z','r','g','b','a'])\n",
    "            subj_idxs = list(np.where(clusters['all_subjs'][:,xc]==s)[0])\n",
    "            for idx in subj_idxs:\n",
    "                ch_name = clusters['ch_names'][idx,clust]\n",
    "                if ch_name != \"EKG1\":\n",
    "                    fif_idx = fif_ch_names.index(ch_name.replace(\"-\",\"\"))\n",
    "                    elecfile_idx = fs_ch_names.index(ch_name.replace(\"-\",\"\"))\n",
    "                    x,y,z = e[elecfile_idx,:]\n",
    "                    r,g,b = across_cluster_cmap[contrast][idx]; a=1.\n",
    "                    new_row = pd.DataFrame({'subj':[s],'hem':[hem],'ch_name':[ch],'x':[x],'y':[y],'z':[z],\n",
    "                                            'r':[r],'g':[g],'b':[b],'a':[a]})\n",
    "                    df = df.append(new_row, ignore_index=True)\n",
    "            df.to_csv(os.path.join(git_path,\"figures\",\"figure_3\",\"csv\",\n",
    "                                   f\"figure_3_cmap_across_clusts_{xc+1}-{yc+1}.csv\"),index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
