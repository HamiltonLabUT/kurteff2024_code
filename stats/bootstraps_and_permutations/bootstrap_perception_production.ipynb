{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrapping sEEG electrode significance\n",
    "We can use a bootstrap _t_-test if we determine a proper baseline in the continuous data. This technique can be seen in [Cheung et al. 2016 _eLife_](https://elifesciences.org/articles/12577):\n",
    "\n",
    "> To identify if a site was responsive to speech sounds, we implemented a bootstrap t-test comparing a site's responses randomly sampled over time during speech sound presentations to responses randomly sampled over time during pre-stimulus silent intervals (p<0.01).\n",
    "\n",
    "In the context of this task we would like to calculate a separate p value for the baseline of the perception trials and the baseline of the production trials. For both of these, the period after the click (but not immediately following) is the best candidate. We can get the baseline times by epoching the clicks 500-1000ms. We choose 1000ms as a cutoff because that is when display of the fixation cross ends and either text is displayed (production) or audio playback begins (perception). Because we have a variable amount of clicks per subject we are going to bootstrap with replacement for all subjects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths - Update locally!\n",
    "git_path = '/path/to/git/kurteff2024_code/'\n",
    "data_path = '/path/to/bids/dataset/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "\n",
    "from img_pipe import img_pipe\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import rcParams as rc\n",
    "import matplotlib.patheffects as PathEffects\n",
    "rc['pdf.fonttype'] = 42\n",
    "plt.style.use('seaborn')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjs = [s for s in os.listdir(\n",
    "    os.path.join(git_path,\"preprocessing\",\"events\",\"csv\")) if \"TCH\" in s or \"S0\" in s]\n",
    "exclude = [\"TCH8\"]\n",
    "no_imaging = [\"S0010\"]\n",
    "subjs = [s for s in subjs if s not in exclude]\n",
    "\n",
    "blocks = {\n",
    "    s: [\n",
    "        b.split(\"_\")[-1] for b in os.listdir(os.path.join(\n",
    "            git_path,\"analysis\",\"events\",\"csv\",s)) if f\"{s}_B\" in b and os.path.isfile(os.path.join(\n",
    "            git_path,\"analysis\",\"events\",\"csv\",s,b,f\"{b}_spkr_sn_all.txt\"\n",
    "        ))\n",
    "    ] for s in subjs\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epoch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "click_tmin, click_tmax = 0.4, 0.6\n",
    "task_tmin, task_tmax = 0.05, 0.55\n",
    "baseline = None\n",
    "epochs, ch_names = dict(), dict()\n",
    "for s in tqdm(subjs):\n",
    "    epochs[s] = dict()\n",
    "    click_epochs, spkr_epochs, mic_epochs = [], [], []\n",
    "    for b in blocks[s]:\n",
    "        blockid = \"_\".join([s,b])\n",
    "        raw = mne.io.read_raw_fif(os.path.join(data_path,f\"{s}_complete\",s,blockid,\n",
    "            \"HilbAA_70to150_8band\",\"ecog_hilbAA70to150.fif\"),preload=True, verbose=False)\n",
    "        fs = raw.info['sfreq']\n",
    "        # Click events\n",
    "        click_eventfile = os.path.join(git_path,\"preprocessing\",\"events\",\"csv\",s,blockid,\n",
    "                                       f\"{blockid}_click_eve.txt\")\n",
    "        with open(click_eventfile,'r') as f:\n",
    "            r = csv.reader(f, delimiter='\\t')\n",
    "            if s not in [\"S0026\",\"TCH14\"]:\n",
    "                events = np.array([[np.ceil(float(row[0])*fs).astype(int),\n",
    "                                    np.ceil(float(row[2])*fs).astype(int),int(float(row[4]))] for row in r])\n",
    "            else:\n",
    "                events = np.loadtxt(click_eventfile).astype(int)\n",
    "                events[:,0] = np.array(events[:,0] * fs).astype(int)\n",
    "                events[:,1] = np.array(events[:,1] * fs).astype(int)\n",
    "        click_epochs.append(mne.Epochs(raw, events, tmin=click_tmin, tmax=click_tmax, baseline=baseline,\n",
    "            preload=True, verbose=False))\n",
    "        # Spkr events\n",
    "        spkr_eventfile = os.path.join(git_path,\"preprocessing\",\"events\",\"csv\",s,blockid,\n",
    "                                      f\"{blockid}_spkr_sn_all.txt\")\n",
    "        with open(spkr_eventfile,'r') as f:\n",
    "            r = csv.reader(f, delimiter='\\t')\n",
    "            events = np.array([[np.ceil(float(row[0])*fs).astype(int),\n",
    "                                np.ceil(float(row[1])*fs).astype(int),int(row[2])] for row in r])\n",
    "        spkr_epochs.append(mne.Epochs(raw, events, tmin=task_tmin, tmax=task_tmax, baseline=baseline,\n",
    "                                      preload=True, verbose=False))\n",
    "        # Mic events\n",
    "        mic_eventfile = os.path.join(git_path,\"preprocessing\",\"events\",\"csv\",s,blockid,\n",
    "                                     f\"{blockid}_mic_sn_all.txt\")\n",
    "        with open(mic_eventfile,'r') as f:\n",
    "            r = csv.reader(f, delimiter='\\t')\n",
    "            events = np.array([[np.ceil(float(row[0])*fs).astype(int),\n",
    "                                np.ceil(float(row[1])*fs).astype(int),int(row[2])] for row in r])\n",
    "        mic_epochs.append(mne.Epochs(raw, events, tmin=task_tmin, tmax=task_tmax, baseline=baseline,\n",
    "                                     preload=True, verbose=False))\n",
    "    epochs[s]['click'] = mne.concatenate_epochs(click_epochs)\n",
    "    epochs[s]['spkr'] = mne.concatenate_epochs(spkr_epochs)\n",
    "    epochs[s]['mic'] = mne.concatenate_epochs(mic_epochs)\n",
    "    ch_names[s] = raw.info['ch_names']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nboots = 1000; pvals = dict()\n",
    "pvals['spkr'] = {s:{ch:0 for ch in ch_names[s]} for s in subjs}\n",
    "pvals['mic'] = {s:{ch:0 for ch in ch_names[s]} for s in subjs}\n",
    "for s in tqdm(subjs):\n",
    "    baseline = epochs[s]['click'].get_data()\n",
    "    spkr_resp = epochs[s]['spkr'].get_data(); mic_resp = epochs[s]['mic'].get_data()\n",
    "    nepochs_click = baseline.shape[0]; nepochs_spkr = spkr_resp.shape[0]; nepochs_mic = mic_resp.shape[0]\n",
    "    for ch_idx, ch in enumerate(ch_names[s]):\n",
    "        spkr_ch_boots, mic_ch_boots = [], []\n",
    "        for n in np.arange(nboots):\n",
    "            # Get a random ten epochs and average across these\n",
    "            baseline_idx = np.random.choice(np.arange(nepochs_click), size=10)\n",
    "            mic_idx = np.random.choice(np.arange(nepochs_mic), size=10)\n",
    "            spkr_idx = np.random.choice(np.arange(nepochs_spkr), size=10)\n",
    "            # Average resp across samples/epochs (chunk of 10)\n",
    "            baseline_chunk = baseline[baseline_idx,ch_idx,:].mean(0).mean(0)\n",
    "            spkr_chunk = spkr_resp[spkr_idx,ch_idx,:].mean(0).mean(0)\n",
    "            mic_chunk = mic_resp[mic_idx,ch_idx,:].mean(0).mean(0)\n",
    "            if baseline_chunk > spkr_chunk:\n",
    "                spkr_ch_boots.append(1)\n",
    "            else:\n",
    "                spkr_ch_boots.append(0)\n",
    "            if baseline_chunk > mic_chunk:\n",
    "                mic_ch_boots.append(1)\n",
    "            else:\n",
    "                mic_ch_boots.append(0)\n",
    "        pvals['spkr'][s][ch] = sum(spkr_ch_boots)/nboots; pvals['mic'][s][ch] = sum(mic_ch_boots)/nboots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to dataframe\n",
    "df = pd.DataFrame(columns = ['subj', 'ch_name', 'spkr_p', 'mic_p'])\n",
    "for s in pvals['spkr'].keys():\n",
    "    ch_names = list(pvals['spkr'][s])\n",
    "    for ch in ch_names:\n",
    "        new_row = pd.DataFrame({'subj':[s], 'ch_name':[ch],\n",
    "                                'spkr_p':[pvals['spkr'][s][ch]], 'mic_p':[pvals['mic'][s][ch]]})\n",
    "        df = df.append(new_row, ignore_index=True)\n",
    "df.to_csv(os.path.join(git_path,\"stats\",\"bootstraps\",\"csv\",\n",
    "    f\"seeg_elec_significance_{len(pvals['spkr'].keys())}_subjs_{nboots}_boots.csv\"), index=False)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
