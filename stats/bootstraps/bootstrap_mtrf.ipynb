{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths - Update locally!\n",
    "git_path = '/path/to/git/kurteff2024_code/'\n",
    "data_path = '/path/to/bids/dataset/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "import random\n",
    "import itertools as itools\n",
    "\n",
    "from img_pipe import img_pipe\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import rcParams as rc\n",
    "import matplotlib.patheffects as PathEffects\n",
    "rc['pdf.fonttype'] = 42\n",
    "plt.style.use('seaborn')\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "sys.path.append(os.path.join(git_path,\"analysis\",\"mtrf\"))\n",
    "import mtrf_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjs = [s for s in os.listdir(\n",
    "    os.path.join(git_path,\"preprocessing\",\"events\",\"csv\")) if \"TCH\" in s or \"S0\" in s]\n",
    "exclude = [\"TCH8\"]\n",
    "no_imaging = [\"S0010\"]\n",
    "subjs = [s for s in subjs if s not in exclude]\n",
    "\n",
    "blocks = {\n",
    "    s: [\n",
    "        b.split(\"_\")[-1] for b in os.listdir(os.path.join(\n",
    "            git_path,\"analysis\",\"events\",\"csv\",s)) if f\"{s}_B\" in b and os.path.isfile(os.path.join(\n",
    "            git_path,\"analysis\",\"events\",\"csv\",s,b,f\"{b}_spkr_sn_all.txt\"\n",
    "        ))\n",
    "    ] for s in subjs\n",
    "}\n",
    "models = ['model1','model2','model3','model4']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load mTRF results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load corrs, best alphas from pandas\n",
    "results_csv_fpath = os.path.join(git_path,\"analysis\",\"mtrf\",\"results.csv\")\n",
    "df = pd.read_csv(results_csv_fpath)\n",
    "# Load stim/resp from hdf5\n",
    "tStims, tResps, vStims, vResps = dict(), dict(), dict(), dict()\n",
    "corrs, best_alphas, ch_names = dict(), dict(), dict()\n",
    "pbar = tqdm(subjs)\n",
    "for s in pbar:\n",
    "    tStims[s], tResps[s], vStims[s], vResps[s] = dict(), dict(), dict(), dict()\n",
    "    corrs[s], best_alphas[s] = dict(), dict()\n",
    "    for m in models:\n",
    "        pbar.set_description(f\"Loading model inputs for {s} {m}\")\n",
    "        # Update this file location accordingly on your local machine!\n",
    "        model_input_h5_fpath = os.path.join(git_path,\"analysis\",\"mtrf\" ,\"h5\",\"model_inputs\",\n",
    "                                            f\"{s}_model_inputs.hdf5\")\n",
    "        tStims[s][m], tResps[s][m], vStims[s][m], vResps[s][m] = mtrf_utils.load_model_inputs(\n",
    "            model_input_h5_fpath, m\n",
    "        )\n",
    "        print(s, m, \"t/v stim:\", tStims[s][m].shape, vStims[s][m].shape, \"||\",\n",
    "              \"t/v resp:\", tResps[s][m].shape, vResps[s][m].shape)  \n",
    "        block = [b.split(\"_\")[-1] for b in os.listdir(os.path.join(\n",
    "            git_path,\"preprocessing\",\"events\",\"csv\",s)) if f\"{b}_mic_sn_all.txt\" in os.listdir(\n",
    "            os.path.join(git_path,\"preprocessing\",\"events\",\"csv\",s,b))][0]\n",
    "        blockid = \"_\".join([s,block])\n",
    "        raw_fpath = os.path.join(data_path,f\"sub-{s}\",blockid,\"HilbAA_70to150_8band\",\"ecog_hilbAA70to150.fif\")\n",
    "        ch_names[s] = mne.io.read_raw_fif(raw_fpath,preload=True,verbose=False).info['ch_names']    \n",
    "        subj_corrs, subj_best_alphas = np.zeros(len(ch_names[s])), np.zeros(len(ch_names[s]))\n",
    "        for i,ch in enumerate(ch_names[s]):\n",
    "            tgt_row = df[(df['subject']==s) & (df['model']==m) & (df['channel']==ch)]\n",
    "            subj_corrs[i] = df.loc[tgt_row.index, 'r_value']\n",
    "            subj_best_alphas[i] = df.loc[tgt_row.index, 'best_alpha']\n",
    "        corrs[s][m] = np.array(subj_corrs)\n",
    "        best_alphas[s][m] = np.array(subj_best_alphas)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delay_min, delay_max = -0.3, 0.5\n",
    "delays = np.arange(np.floor(delay_min*100),np.ceil(delay_max*100),dtype=int)\n",
    "pvals = dict(); nboots_shuffle = 100; chunklen = len(delays)*3 # data randomized in chunks\n",
    "for s in subjs:\n",
    "    pvals[s] = dict()\n",
    "    for m in models:\n",
    "        nsamps, nelecs = tResps[s][m].shape\n",
    "        allinds = range(nsamps); nchunks = int(np.floor(0.2*nsamps/chunklen)); boot_corrs = []\n",
    "        # Run the bootstrap\n",
    "        pbar = tqdm(np.arange(nboots_shuffle))\n",
    "        for n in pbar:\n",
    "            pbar.set_description(f'{s} {m} Bootstrap {n}/{nboots_shuffle}')\n",
    "            indchunks = list(zip(*[iter(allinds)]*chunklen)); random.shuffle(indchunks)\n",
    "            shuff_inds = list(itools.chain(*indchunks[:nchunks]))\n",
    "            tStim_shuff = tStims[s][m].copy(); tResp_shuff = tResps[s][m].copy()\n",
    "            tStim_shuff = tStim_shuff[shuff_inds,:]; tResp_shuff = tResp_shuff[:len(shuff_inds),:]\n",
    "            boot_corr = mtrf_utils.eigridge_corr(tStim_shuff, vStims[s][m], tResp_shuff, vResps[s][m],\n",
    "                                 [best_alphas[s][m][0]], corrmin = 0.05)\n",
    "            boot_corrs.append(boot_corr)\n",
    "        boot_corrs = np.vstack((boot_corrs))\n",
    "        # Compare bootstrap coors to STRF corrs\n",
    "        # Is the correlation of the model greater than the shuffled correlation for random data?\n",
    "        strf_corrs = corrs[s][m]\n",
    "        h_val = np.array([strf_corrs > boot_corrs[c] for c in np.arange(len(boot_corrs))])\n",
    "        print(h_val.shape) # Should be nboots x nchans\n",
    "        # Count the number of times out of nboots_shuffle that the correlation is greater than \n",
    "        # random, subtract from 1 to get the bootstrapped p_val (one per electrode)\n",
    "        pvals[s][m] = 1-h_val.sum(0)/nboots_shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to csv\n",
    "results_csv_fpath = os.path.join(git_path,\"analysis\",\"mtrf\",\"results.csv\")\n",
    "df = pd.read_csv(results_csv_fpath)\n",
    "pbar = tqdm(subjs)\n",
    "for s in pbar:\n",
    "    for m in models:\n",
    "        pbar.set_description(f\"Saving pvals for {s} {m} to csv\")\n",
    "        for i,ch in enumerate(ch_names[s]):\n",
    "            tgt_row = df[(df['subject']==s) & (df['model']==m) & (df['channel']==ch)]\n",
    "            df.loc[tgt_row.index, 'p_value'] = pvals[s][m][i]\n",
    "df.to_csv(results_csv_fpath,index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
